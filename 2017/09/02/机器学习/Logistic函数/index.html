<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="来自cs的一名渣硕"><title>Logistic函数 | yitakabe</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Logistic函数</h1><a id="logo" href="/.">yitakabe</a><p class="description">A good brain is not as good as a rotten pen</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/books/"><i class="fa fa-book"> 书籍</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Logistic函数</h1><div class="post-meta">Sep 2, 2017<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span></div><div class="post-content"><h1 id="1、Logistic函数推导"><a href="#1、Logistic函数推导" class="headerlink" title="1、Logistic函数推导"></a>1、Logistic函数推导</h1><a id="more"></a>
<p>&emsp;&emsp;Logistic回归模型中，因变量只有0和1两种情况。假设在$p$个独立自变量${x}_{1}$,${x}_{2}$,…,${x}_{p}$,的作用下，记$y$取1的概率是$p=P(y=1|X)$，则取0的概率是$1-p$。那么取1和取0的概率之比为$\frac{p}{1-p}$，该比值称为<strong>发生比</strong>（odds）。两个不同时间的发生比之比称为<strong>优势比</strong>，$\frac{p1}{1-p1}/\frac{p2}{1-p2}$。Logistic一般用发生比odds进行解释。<br>&emsp;&emsp;对发生比取自然对数即为$$Logit(p)=ln(\frac{p}{1-p})$$<br>&emsp;&emsp;令$Logit(p)=Z$，通过化简即可得到$p=\frac{1}{1+e^{-z}}$。$p=\frac{1}{1+e^{-z}}$就是Logistic函数。<br>&emsp;&emsp;因为$p$在$(0,1)$取值，则$Logit(p)$在$(0,+\propto)$取值，Logistic函数在$(-\propto,+\propto)$取值。</p>
<h1 id="2、Logistic回归模型"><a href="#2、Logistic回归模型" class="headerlink" title="2、Logistic回归模型"></a>2、Logistic回归模型</h1><p>&emsp;&emsp;Logistic回归模型是建立在$ln(\frac{p}{1-p})$与自然变量的线性回归模型。Logistic回归模型的公式为：$$ln(\frac{p}{1-p})={\beta}_{0}+{\beta}_{1}{x}_{1}+…+{\beta}_{p}{x}_{p}+\varepsilon $$<br>&emsp;&emsp;因为$ln(\frac{p}{1-p})$的取值是$(-\propto,+\propto)$,所以自然变量${x}_{1}$,${x}_{2}$,…,${x}_{p}$的取值是任意范围的。<br>&emsp;&emsp;记$g(x)={\beta}_{0}+{\beta}_{1}{x}_{1}+…+{\beta}_{p}{x}_{p}$，得到$p=\frac{1}{1+e^{-g(x)}}$，$1-p=\frac{1}{1+e^{g(x)}}$。<strong>此处忽略$\varepsilon$</strong>。</p>
<h1 id="3、Logistic回归模型的建模步骤"><a href="#3、Logistic回归模型的建模步骤" class="headerlink" title="3、Logistic回归模型的建模步骤"></a>3、Logistic回归模型的建模步骤</h1><ol>
<li>根据目标数据设置指标变量(因变量、自变量)，然后收集数据。</li>
<li>用$ln(\frac{p}{1-p})$和自变量列出回归方程，估计出模型中的回归系数。$$ln(\frac{p}{1-p})={\beta}_{0}+{\beta}_{1}{x}_{1}+…+{\beta}_{p}{x}_{p} $$</li>
<li>进行模型检验，根据输出的方差分析表中的$F$值和$p$值来检验该回归方程是否显著。如果$p$值小于显著水平$\alpha$则模型通过检验，可以进行下一步回归系数的检验，否则重新选择指标变量，重新建立回归方程。</li>
<li>在多元线性回归中，并不是每个自变量都会对$y$产生显著的影响，需要对每一个自变量都进行显著性检验，使得那些次要可有可无的变量不参与回归过程，去除之后便可建立更加简单有效的回归方程。</li>
<li>模型应用。</li>
</ol>
<h1 id="4、对一般Logistic模型系数的解释"><a href="#4、对一般Logistic模型系数的解释" class="headerlink" title="4、对一般Logistic模型系数的解释"></a>4、对一般Logistic模型系数的解释</h1><p><br></p>
<blockquote>
<p>该部分引用<a href="http://www.jianshu.com/p/89c6e5ebea34?winzoom=1" target="_blank" rel="external">这里</a></p>
</blockquote>
<p>&emsp;&emsp;广义的线性模型由三部分组成：随机部分、系统部分和连接部分。直观地理解这种差异：将两种模型都视为广义线性模型的特殊形式。广义线性模型由三个部分组成：随机部分、系统部分和连接部分。</p>
<p>&emsp;&emsp;随机部分指的是变量Y以及Y的概率分布，传统线性模型Y是连续变量并假设其服从正态分布。在经典logistic回归中，Y是一个二分变量并服从二项式分布。</p>
<p>&emsp;&emsp;系统部分指的是解释变量以及这些解释变量如何组合在一起构成了解释方程，在传统线性模型和logistic回归中都是这样：${\beta}_{0}+{\beta}_{1}{x}_{1}+…+{\beta}_{p}{x}_{p}$ ，这个表达通常被称为线性预测（linear predictor），而x与其他解释变量还可以结合（如相乘交互），因此可以做出其实非线性的预测。</p>
<p>&emsp;&emsp;连接部分说明了Y的均值 μ =E（Y）如何与线性预测相联系。</p>
<blockquote>
<p>其实说白了就是，随机部分规定了 Y，系统部分规定了 X，而连接部分就是用一个连接函数（link function）将 X 与 Y连了起来，也就是我们经常看到的回归方程，它所反映的是 x 的变化带来的 Y 的均值的变化。</p>
</blockquote>
<p>&emsp;&emsp;对Logit模型系数解释的一个总的原则是：方向看系数，大小看exp(系数)，不管自变量是连续变量还是虚拟变量 or 其他。</p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>yitakabe</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2017/09/02/机器学习/Logistic函数/">http://yoursite.com/2017/09/02/机器学习/Logistic函数/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="http://yoursite.com/2017/09/02/机器学习/Logistic函数/" data-id="cjjskwy2l000blwho8v934cr8" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACMElEQVR42u3ay07DMBAF0P7/TxeJFSxI77UToJPjVVSVxCeVhnn48YjX83Mdf/L185++//Xz5+F6XLEwMDDelpHc7vgxz2Ad3+f4OqJiYGDcgHEcZPPwmiDz4J7sDQMDA2MtsctDcPtSMDAwMBJGkiYmwRcDAwOjZSTFZ9J6a0vfP6jFMTAw3pDRDgZ+8/rC+QYGBsabMM4qPveHlzu7wsDAmM3YSeau2Ghyt6gWx8DAGMRYbGyViWPbkquHmhgYGKMZefs+f1h+CKwdi77YOQYGxmjGziPXAnQ7YCgOmWFgYIxj5M2s9rBFO57cOuqBgYExmnFWW39tnNC21aJQjoGBMY6RP6Dta+XpY7uHF8NLDAyMoYydcWOLaceW0YvDwMC4AeOsRthaEbv2Ir5dY2BgjGbsJ4j1iLE8fFYEYgwMjNGMZNNrh8CSb7aM4rAFBgbGIMbO8HK/oG1fZXFaBAMDYxyjDZFJY65tsbVDUwwMjDswkmSuLVB3Ct3FgIuBgTGakQ8Ddo5ttcPRtbQSAwNjKmOtEM0PUuQB/YRfAAMDYyij/YO1cePOELT9l4CBgTGP8SzXThO/fTV52w4DA2M2I1872z1OEPPhxNrREAwMjBmMvPhsH59vvQ240bvEwMAYx7hiuJgPA/Kg/yLPxcDAwAg22iaUbfOuzl4xMDBuxsgHAG2i2aahGBgY92TsF7H5QHQ/0byw3YaBgfEvGTuDgZ3t5snfCQAMDIx3ZXwALb884ktrrf0AAAAASUVORK5CYII=">分享</a><div class="tags"><a href="/tags/机器学习/">机器学习</a><a href="/tags/Logistic/">Logistic</a></div><div class="post-nav"><a class="pre" href="/2017/09/02/机器学习/机器学习简介/">机器学习简介</a><a class="next" href="/2017/08/30/数据处理/数据分析/数据质量分析/">数据质量分析</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/前端/">前端</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/嵌入式/">嵌入式</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数字信号处理/">数字信号处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/函数指针/" style="font-size: 15px;">函数指针</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/pipenv/" style="font-size: 15px;">pipenv</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/Logistic/" style="font-size: 15px;">Logistic</a> <a href="/tags/前端/" style="font-size: 15px;">前端</a> <a href="/tags/VueJS/" style="font-size: 15px;">VueJS</a> <a href="/tags/三要素/" style="font-size: 15px;">三要素</a> <a href="/tags/数据分析/" style="font-size: 15px;">数据分析</a> <a href="/tags/RK3188/" style="font-size: 15px;">RK3188</a> <a href="/tags/Wifi/" style="font-size: 15px;">Wifi</a> <a href="/tags/蓝牙/" style="font-size: 15px;">蓝牙</a> <a href="/tags/Android5-1/" style="font-size: 15px;">Android5.1</a> <a href="/tags/梯度下降/" style="font-size: 15px;">梯度下降</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/时间序列/" style="font-size: 15px;">时间序列</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/05/30/Python/pipenv的基本使用/">pipenv的基本使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/07/前端/Vue/Vue2学习笔记/">Vue2.0 学习笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/03/Docker/Docker基本使用/">Docker镜像的基本操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/07/嵌入式/编程/通过函数指针进行初始化/">通过函数指针进行初始化</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/03/机器学习/梯度下降-吴恩达公开课笔记/梯度下降-吴恩达公开课笔记/">梯度下降(吴恩达公开课笔记)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/02/数据处理/数据处理算法/时间序列算法/时间序列算法/">时间序列算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/02/机器学习/机器学习简介/">机器学习简介</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/02/机器学习/Logistic函数/">Logistic函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/30/数据处理/数据分析/数据质量分析/">数据质量分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/30/嵌入式/调试记录/基于RK3188平台与Android5.1的AP6212蓝牙与wifi调试记录/">基于RK3188平台与Android5.1的AP6212蓝牙与wifi调试记录</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">yitakabe.</a><!--|  Powered by--><!--a(rel='nofollow', target='_blank', href='https://hexo.io')  Hexo.--><!--a(rel='nofollow', target='_blank', href='https://github.com/tufu9441/maupassant-hexo')  Theme--><!--|  by--><!--a(rel='nofollow', target='_blank', href='https://github.com/pagecho')  Cho.--></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>